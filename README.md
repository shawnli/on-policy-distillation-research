# On-Policy Distillation è°ƒç ”èµ„æ–™

æœ¬ä»“åº“æ”¶é›†äº†å…³äº On-Policy Distillation çš„å­¦æœ¯è®ºæ–‡ã€ä»£ç å®ç°å’ŒæŠ€æœ¯èµ„æ–™ã€‚

## ğŸ“š è®ºæ–‡

### ICLR 2024: On-Policy Distillation of Language Models
- **ä½œè€…**: Rishabh Agarwal et al. (Google Brain)
- **ä¼šè®®**: ICLR 2024
- **æ–¹æ³•**: Generalized Knowledge Distillation (GKD)
- **è®ºæ–‡**: [On-Policy_Distillation_ICLR2024.pdf](./On-Policy_Distillation_ICLR2024.pdf)
- **arXiv**: https://arxiv.org/abs/2306.13649
- **å¼•ç”¨**: 203+

### Thinking Machines Lab åšå®¢
- **æ ‡é¢˜**: On-Policy Distillation
- **ä½œè€…**: Kevin Lu et al.
- **æ—¥æœŸ**: 2025-10-27
- **é“¾æ¥**: https://thinkingmachines.ai/blog/on-policy-distillation/

## ğŸ’» ä»£ç å®ç°

### 1. Hugging Face TRL
ä½äº `trl/` ç›®å½•ï¼ŒåŒ…å«ä»¥ä¸‹å®ç°ï¼š

- **GKDTrainer**: Generalized Knowledge Distillation
  - é…ç½®: `trl/trainer/gkd_config.py`
  - è®­ç»ƒå™¨: `trl/trainer/gkd_trainer.py`
  - ç¤ºä¾‹: `examples/scripts/gkd.py`
  - æ–‡æ¡£: `docs/source/gkd_trainer.md`

- **GOLD Trainer**: General On-Policy Logit Distillation
  - å®ç°: `trl/experimental/gold/`
  - æ–‡æ¡£: `docs/source/gold_trainer.md`

- **MiniLLM Trainer**: TML On-Policy Distillation çš„æ³›åŒ–ç‰ˆæœ¬
  - å®ç°: `trl/experimental/minillm/`
  - æ–‡æ¡£: `docs/source/minillm_trainer.md`

**ä»“åº“**: https://github.com/huggingface/trl
**Stars**: 16.6k

### 2. Thinking Machines Lab - Tinker Cookbook
ä½äº `tinker-cookbook/` ç›®å½•ï¼Œå®˜æ–¹å®ç°å’Œç¤ºä¾‹ã€‚

**ä»“åº“**: https://github.com/thinking-machines-lab/tinker-cookbook
**Stars**: 2.3k

## ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ

On-Policy Distillation ç»“åˆäº†å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å’Œç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰çš„ä¼˜åŠ¿ï¼š

| æ–¹æ³• | é‡‡æ ·æ–¹å¼ | å¥–åŠ±ä¿¡å· |
|------|---------|---------|
| SFT (ç›‘ç£å¾®è°ƒ) | Off-policy | å¯†é›† |
| RL (å¼ºåŒ–å­¦ä¹ ) | On-policy | ç¨€ç– |
| On-Policy Distillation | On-policy | å¯†é›† |

### å…³é”®ä¼˜åŠ¿
1. **è®­ç»ƒæ•ˆç‡æå‡**: ç›¸æ¯” SFT éœ€è¦ 200ä¸‡ promptsï¼ŒOPD åªéœ€ 77K
2. **æŒç»­å­¦ä¹ **: ç¼“è§£ç¾éš¾æ€§é—å¿˜é—®é¢˜
3. **Token çº§åé¦ˆ**: åœ¨æ¯ä¸ª token ä¸Šæä¾›å¯†é›†çš„ç›‘ç£ä¿¡å·

## ğŸ“– æŠ€æœ¯ç»†èŠ‚

è¯¦è§ [æŠ€æœ¯åŸç†è¯´æ˜æ–‡æ¡£](./æŠ€æœ¯åŸç†è¯´æ˜.md)

## ğŸ”— ç›¸å…³èµ„æº

- [Hugging Face åšå®¢: Unlocking On-Policy Distillation](https://huggingface.co/spaces/HuggingFaceH4/on-policy-distillation)
- [OpenReview è®ºæ–‡è®¨è®º](https://openreview.net/forum?id=3zKtaqxLhW)
- [çŸ¥ä¹æ–‡ç« è§£è¯»](https://www.zhihu.com/pin/1968462515513062544)

## ğŸ“ å¼•ç”¨

```bibtex
@inproceedings{agarwal2024onpolicy,
  title={On-Policy Distillation of Language Models: Learning from Self-Generated Mistakes},
  author={Agarwal, Rishabh and others},
  booktitle={International Conference on Learning Representations},
  year={2024}
}
```

## ğŸ“„ è®¸å¯è¯

- TRL: Apache-2.0 License
- Tinker Cookbook: Apache-2.0 License
